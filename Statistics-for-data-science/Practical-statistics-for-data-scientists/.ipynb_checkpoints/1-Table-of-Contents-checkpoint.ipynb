{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents ([link](https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/?utm_medium=referral&utm_campaign=publisher&utm_source=oreilly&utm_content=buybox))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploratory Data Analysis\n",
    "* Elements of Structured Data\n",
    "    * Further Reading\n",
    "* Rectangular Data\n",
    "    * Data Frames and Indexes\n",
    "    * Nonrectangular Data Structures\n",
    "    * Further Reading\n",
    "* Estimates of Location\n",
    "    * Mean\n",
    "    * Median and Robust Estimates\n",
    "    * Example: Location Estimates of Population and Murder Rates\n",
    "    * Further Reading\n",
    "* Estimates of Variability\n",
    "    * Standard Deviation and Related Estimates\n",
    "    * Estimates Based on Percentiles\n",
    "    * Example: Variability Estimates of State Population\n",
    "    * Further Reading\n",
    "* Exploring the Data Distribution\n",
    "    * Percentiles and Boxplots\n",
    "    * Frequency Table and Histograms\n",
    "    * Density Estimates\n",
    "    * Further Reading\n",
    "* Exploring Binary and Categorical Data\n",
    "    * Mode\n",
    "    * Expected Value\n",
    "    * Further Reading\n",
    "* Correlation\n",
    "    * Scatterplots\n",
    "    * Further Reading\n",
    "* Exploring Two or More Variables\n",
    "    * Hexagonal Binning and Contours (Plotting Numeric versus Numeric Data)\n",
    "    * Two Categorical Variables\n",
    "    * Categorical and Numeric Data\n",
    "    * Visualizing Multiple Variables\n",
    "    * Further Reading\n",
    "* Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data and Sampling Distributions\n",
    "\n",
    "* Random Sampling and Sample Bias\n",
    "    * Bias\n",
    "    * Random Selection\n",
    "    * Size versus Quality: When Does Size Matter?\n",
    "    * Sample Mean versus Population Mean\n",
    "    * Further Reading\n",
    "* Selection Bias\n",
    "    * Regression to the Mean\n",
    "    * Further Reading\n",
    "* Sampling Distribution of a Statistic\n",
    "    * Central Limit Theorem\n",
    "    * Standard Error\n",
    "    * Further Reading\n",
    "* The Bootstrap\n",
    "    * Resampling versus Bootstrapping\n",
    "    * Further Reading\n",
    "* Confidence Intervals\n",
    "    * Further Reading\n",
    "* Normal Distribution\n",
    "    * Standard Normal and QQ-Plots\n",
    "* Long-Tailed Distributions\n",
    "    * Further Reading\n",
    "* Student’s t-Distribution\n",
    "    * Further Reading\n",
    "* Binomial Distribution\n",
    "    * Further Reading\n",
    "* Poisson and Related Distributions\n",
    "    * Poisson Distributions\n",
    "    * Exponential Distribution\n",
    "    * Estimating the Failure Rate\n",
    "    * Weibull Distribution\n",
    "    * Further Reading\n",
    "* Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3. Statistical Experiments and Significance Testing\n",
    "\n",
    "* A/B Testing\n",
    "    * Why Have a Control Group?\n",
    "    * Why Just A/B? Why Not C, D…?\n",
    "    * For Further Reading\n",
    "* Hypothesis Tests\n",
    "    * The Null Hypothesis\n",
    "    * Alternative Hypothesis\n",
    "    * One-Way, Two-Way Hypothesis Test\n",
    "    * Further Reading\n",
    "* Resampling\n",
    "    * Permutation Test\n",
    "    * Example: Web Stickiness\n",
    "    * Exhaustive and Bootstrap Permutation Test\n",
    "    * Permutation Tests: The Bottom Line for Data Science\n",
    "    * For Further Reading\n",
    "* Statistical Significance and P-Values\n",
    "    * P-Value\n",
    "    * Alpha\n",
    "    * Type 1 and Type 2 Errors\n",
    "    * Data Science and P-Values\n",
    "    * Further Reading\n",
    "* t-Tests\n",
    "    * Further Reading\n",
    "* Multiple Testing\n",
    "    * Further Reading\n",
    "* Degrees of Freedom\n",
    "    * Further Reading\n",
    "* ANOVA\n",
    "    * F-Statistic\n",
    "    * Two-Way ANOVA\n",
    "    * Further Reading\n",
    "* Chi-Square Test\n",
    "    * Chi-Square Test: A Resampling Approach\n",
    "    * Chi-Square Test: Statistical Theory\n",
    "    * Fisher’s Exact Test\n",
    "    * Relevance for Data Science\n",
    "    * Further Reading\n",
    "* Multi-Arm Bandit Algorithm\n",
    "    * Further Reading\n",
    "* Power and Sample Size\n",
    "    * Sample Size\n",
    "    * Further Reading\n",
    "* Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regression and Prediction\n",
    "\n",
    "    Simple Linear Regression\n",
    "        The Regression Equation\n",
    "        Fitted Values and Residuals\n",
    "        Least Squares\n",
    "        Prediction versus Explanation (Profiling)\n",
    "        Further Reading\n",
    "    Multiple Linear Regression\n",
    "        Example: King County Housing Data\n",
    "        Assessing the Model\n",
    "        Cross-Validation\n",
    "        Model Selection and Stepwise Regression\n",
    "        Weighted Regression\n",
    "        Further Reading\n",
    "    Prediction Using Regression\n",
    "        The Dangers of Extrapolation\n",
    "        Confidence and Prediction Intervals\n",
    "    Factor Variables in Regression\n",
    "        Dummy Variables Representation\n",
    "        Factor Variables with Many Levels\n",
    "        Ordered Factor Variables\n",
    "    Interpreting the Regression Equation\n",
    "        Correlated Predictors\n",
    "        Multicollinearity\n",
    "        Confounding Variables\n",
    "        Interactions and Main Effects\n",
    "    Testing the Assumptions: Regression Diagnostics\n",
    "        Outliers\n",
    "        Influential Values\n",
    "        Heteroskedasticity, Non-Normality and Correlated Errors\n",
    "        Partial Residual Plots and Nonlinearity\n",
    "    Polynomial and Spline Regression\n",
    "        Polynomial\n",
    "        Splines\n",
    "        Generalized Additive Models\n",
    "        Further Reading\n",
    "    Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classification\n",
    "\n",
    "    Naive Bayes\n",
    "        Why Exact Bayesian Classification Is Impractical\n",
    "        The Naive Solution\n",
    "        Numeric Predictor Variables\n",
    "        Further Reading\n",
    "    Discriminant Analysis\n",
    "        Covariance Matrix\n",
    "        Fisher’s Linear Discriminant\n",
    "        A Simple Example\n",
    "        Further Reading\n",
    "    Logistic Regression\n",
    "        Logistic Response Function and Logit\n",
    "        Logistic Regression and the GLM\n",
    "        Generalized Linear Models\n",
    "        Predicted Values from Logistic Regression\n",
    "        Interpreting the Coefficients and Odds Ratios\n",
    "        Linear and Logistic Regression: Similarities and Differences\n",
    "        Assessing the Model\n",
    "        Further Reading\n",
    "    Evaluating Classification Models\n",
    "        Confusion Matrix\n",
    "        The Rare Class Problem\n",
    "        Precision, Recall, and Specificity\n",
    "        ROC Curve\n",
    "        AUC\n",
    "        Lift\n",
    "        Further Reading\n",
    "    Strategies for Imbalanced Data\n",
    "        Undersampling\n",
    "        Oversampling and Up/Down Weighting\n",
    "        Data Generation\n",
    "        Cost-Based Classification\n",
    "        Exploring the Predictions\n",
    "        Further Reading\n",
    "    Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Statistical Machine Learning\n",
    "\n",
    "    K-Nearest Neighbors\n",
    "        A Small Example: Predicting Loan Default\n",
    "        Distance Metrics\n",
    "        One Hot Encoder\n",
    "        Standardization (Normalization, Z-Scores)\n",
    "        Choosing K\n",
    "        KNN as a Feature Engine\n",
    "    Tree Models\n",
    "        A Simple Example\n",
    "        The Recursive Partitioning Algorithm\n",
    "        Measuring Homogeneity or Impurity\n",
    "        Stopping the Tree from Growing\n",
    "        Predicting a Continuous Value\n",
    "        How Trees Are Used\n",
    "        Further Reading\n",
    "    Bagging and the Random Forest\n",
    "        Bagging\n",
    "        Random Forest\n",
    "        Variable Importance\n",
    "        Hyperparameters\n",
    "    Boosting\n",
    "        The Boosting Algorithm\n",
    "        XGBoost\n",
    "        Regularization: Avoiding Overfitting\n",
    "        Hyperparameters and Cross-Validation\n",
    "    Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Unsupervised Learning\n",
    "\n",
    "    Principal Components Analysis\n",
    "        A Simple Example\n",
    "        Computing the Principal Components\n",
    "        Interpreting Principal Components\n",
    "        Further Reading\n",
    "    K-Means Clustering\n",
    "        A Simple Example\n",
    "        K-Means Algorithm\n",
    "        Interpreting the Clusters\n",
    "        Selecting the Number of Clusters\n",
    "    Hierarchical Clustering\n",
    "        A Simple Example\n",
    "        The Dendrogram\n",
    "        The Agglomerative Algorithm\n",
    "        Measures of Dissimilarity\n",
    "    Model-Based Clustering\n",
    "        Multivariate Normal Distribution\n",
    "        Mixtures of Normals\n",
    "        Selecting the Number of Clusters\n",
    "        Further Reading\n",
    "    Scaling and Categorical Variables\n",
    "        Scaling the Variables\n",
    "        Dominant Variables\n",
    "        Categorical Data and Gower’s Distance\n",
    "        Problems with Clustering Mixed Data\n",
    "    Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
